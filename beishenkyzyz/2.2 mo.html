<!DOCTYPE html>
<html lang="en">
   <head>
      <meta charset="UTF-8">
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      <link href="css/styles.css" rel="stylesheet">
      <title>Zharkynai Beishen kyzy | Portfolio</title>
   </head>
   <body>
<!-- Page Header  -->
      <header class="page-header">
         <h1>Portfolio</h1>
      </header>
<!-- Main Content Area  -->
      <main>
<!-- Module 1.1 Blog Post Starts here -->
         <article class="hidden">
         <header class="article-header">
            <h2>Module 1.1 Blog Post</h2>
         </header>
         <h3>Why Systems Thinking Matters in a Complex Digital World</h3>
         <p>Systems thinking is about looking at the bigger picture. Instead of focusing on one part of a system in isolation, it helps us see how all the pieces connect, influence each other, and work as a whole. I like to think of it like looking at a forest rather than just one tree. In a digital environment, this means understanding how users, hardware, software, networks, and even organizations interact, not just how each works individually.            </p>
         <h3>Systems Thinking vs. Traditional Thinking</h3>
         <p>Traditional thinking is often linear. It follows a straight path: problem → solution. While this can work for simple tasks, it falls short when we deal with complex systems where things aren’t so clear-cut. For example, fixing one issue in a system might unintentionally cause problems somewhere else. Systems thinking helps us anticipate those side effects by considering feedback loops, delays, and interdependencies. According to Holt (2019), this way of thinking shifts our focus from isolated components to patterns and behaviors across a system’s lifecycle.</p>
         <h3>Why Model-Based Thinking Works Better for Digital Systems</h3>
         <p>Designing complex digital systems—like cloud platforms, smart home networks, or enterprise software—requires more than trial and error. This is where model-based systems engineering (MBSE) comes in. MBSE uses visual models, like diagrams or flowcharts, to map out a system's architecture before anything is built. These models let teams test ideas, identify weak points, and collaborate better. As INCOSE (2023) explains, model-based approaches reduce risk and help make systems more adaptable to change, which is essential in fast-moving tech environments.</p>
         <p> One good example is how autonomous vehicles are built. You cant just code something and hope it works. You need models that simulate sensors, responses, user behavior, and traffic—all before anything hits the road. These models show how systems interact, fail, or succeed, all without real-world consequences.</p>
         <h3>Final Thoughts</h3>
         <p>In a world where digital systems are becoming more intertwined with our daily lives, understanding systems thinking isnt just helpful—it’s necessary. It lets us plan smarter, think deeper, and build more sustainable solutions. As Jackson (2021) puts it, systems thinking helps us design not only for functionality, but for adaptability, longevity, and real-world complexity.</p>
         <footer>
         <h3>Sources:</h3>
         <ol>
             <li>Holt, J. (2019). Systems engineering demystified. Packt Publishing.</a></li>
             <li>INCOSE. (2023). INCOSE Systems Engineering Handbook: A Guide for System Life Cycle Processes and Activities (5th ed.). Wiley.</li>
             <li>Jackson, S. (2021). Systems Thinking: Creative Holism for Managers. Wiley.</li>
             </ol>
     </footer>
  </article>
<!-- Module 1.2 Blog Post Starts here -->
         <article class="hidden">
            <header>
              <h2>Systems Thinking: A New Way to See the World</h2>
              <p><em>By Nai</em></p>
            </header>
            <section>
              <p>When I first came across the term “systems thinking,” I honestly thought it was just another technical phrase thrown around in management and engineering fields—probably something about improving workflows or optimizing structures. I didn’t expect it to become a mindset that would genuinely change the way I interpret challenges, decisions, and even daily life. But the more I explored it, especially through <em>Systems Engineering Demystified</em> by Holt (2019), the more I realized how deep and transformative systems thinking really is. It’s not just a tool used by engineers or IT professionals. It’s a lens, a worldview, and a way of interacting with complexity that’s becoming more relevant by the day.</p>
        
              <p>So, what exactly is systems thinking? In simple terms, it’s an approach to understanding and solving problems by seeing how different elements interact within a whole. Rather than breaking things down into isolated parts and treating them as separate, systems thinking asks you to look at the bigger picture. It’s about recognizing patterns, feedback loops, delays, unintended consequences, and relationships between parts. It’s a shift from linear thinking—where A causes B, and B causes C—to circular, dynamic thinking, where everything influences everything else. It’s messier than traditional problem-solving, but it also gets you closer to the root causes of problems rather than just treating symptoms.</p>
        
              <p>One of the best ways to explain systems thinking is by using real-life examples. Take traffic congestion. A traditional thinker might suggest building more lanes to reduce traffic during rush hour. But a systems thinker would ask more questions: Why are so many people on the road at the same time? What factors contribute to this congestion? Maybe it’s related to poorly planned work hours, limited public transportation, or even the location of schools and businesses. Maybe building more lanes could temporarily ease traffic, but in the long run, it might actually increase car usage and lead to more congestion—a phenomenon known as induced demand. Systems thinking forces you to look beyond the obvious and understand how different factors create patterns over time (Holt, 2019).</p>
        
              <p>What’s even more interesting is how systems thinking makes you reflect not only on technical systems but on personal decisions too. I’ve started applying it in my own routines. For example, I used to blame procrastination purely on lack of discipline. But now, I ask myself what’s really going on: Is the task unclear? Am I overwhelmed by other responsibilities? Is my workspace affecting my focus? By looking at these interconnected causes instead of just labeling myself as “lazy,” I’ve actually been able to design better study strategies and daily routines. That’s one of the most empowering things about systems thinking—it’s not about control, it’s about understanding. When you understand a system, you can work with it rather than against it.</p>
        
              <p>Another major shift systems thinking encourages is embracing complexity instead of avoiding it. In traditional thinking, especially in school, we’re taught to simplify problems, strip away variables, and find the most direct solution. But life isn’t that simple. And neither are the systems we work with in IT or business. Systems thinking says: yes, it’s complex—and that’s okay. Instead of flattening the complexity, it teaches us to map it out, identify relationships, and look for leverage points. Leverage points are places in a system where a small shift can lead to significant changes. Donella Meadows (2008), one of the most well-known voices in this field, explains that understanding where and how to intervene in a system is far more powerful than trying to force change blindly.</p>
        
              <p>In digital environments especially, this mindset is crucial. Every app, platform, or system we interact with is made up of smaller components that are constantly talking to each other. A bug in one feature can cascade through the entire platform if the dependencies aren’t managed properly. Let’s say a company wants to improve its website load time. A simple fix might be compressing images. But a systems thinker would pause and ask: how does this affect user experience? What about visual clarity on different devices? Could it impact branding perception or increase bounce rates? Suddenly, what seemed like a technical fix becomes a layered decision involving design, business goals, and customer behavior. Berman and Korsten (2021) highlight this in their work on digital transformation, emphasizing the need for “digital integrators”—professionals who don’t just understand technology, but how that technology fits into larger human and organizational systems.</p>
        
              <p>I saw this in action during a group project for a system design course. We were building a simple inventory management tool. At first, we divided the tasks: login page, product entry form, and database connections. Everyone focused on their piece. But when we finally tried to test the whole system, things didn’t flow. Error messages popped up. Buttons weren’t triggering the right functions. That’s when we realized we were thinking in silos. We stopped, got together, and created a flow diagram of the system. As we mapped the connections, things made more sense. We spotted inefficiencies and overlaps. We adjusted our approach—not just technically, but mentally. That was the moment I saw systems thinking in real-time. Instead of looking at tasks as isolated checkboxes, we started seeing them as parts of a living, breathing system that required coordination and shared understanding. Holt (2019) explains this as moving from a component-based view to a systems-oriented one—where individual success doesn’t matter unless the whole system functions well.</p>
        
              <p>What I also love about systems thinking is that it encourages humility. It teaches you to stop pretending you have all the answers and instead approach problems with curiosity. That humility is essential in today’s world, where things change quickly and nothing operates in isolation. Systems thinkers don’t rush to solve problems—they pause, observe, ask deeper questions, and recognize that sometimes, the most impactful solutions aren’t immediate or obvious. This approach has helped me not just academically, but emotionally too. In group settings, instead of jumping in with assumptions, I’ve started listening more, trying to see where everyone’s coming from. That shift—small but meaningful—has made my teamwork more collaborative and less stressful.</p>
        
              <p>Another huge part of systems thinking is the use of models. These aren’t just fancy charts—they’re visual tools that help you make sense of complexity. A model might be a causal loop diagram, a data flow chart, or a system map. The point is, models help you see relationships you might miss in a list or a table. When we drew our system map during the inventory project, we noticed two data inputs going into the same processing point, causing duplicate entries. That model wasn’t just a diagram; it was a lens that revealed problems we hadn’t considered. Holt (2019) notes that models act like bridges between abstract understanding and real-world implementation. They don’t just represent systems—they help shape the way we think about and engage with them.</p>
        
              <p>Looking ahead, I know that systems thinking will continue to play a major role in my development, especially as I move toward a career in cybersecurity and IT systems management. Threats in cybersecurity often come from small vulnerabilities that ripple into major consequences—like the SolarWinds breach, where a single compromised software update impacted dozens of organizations. You can’t manage cybersecurity risks effectively without thinking in systems. You need to understand how software updates, user behavior, third-party vendors, and data storage all connect. It’s not just about firewalls—it’s about awareness, feedback loops, and long-term resilience. That’s why systems thinking is becoming a core skill for anyone working in tech.</p>
        
              <p>But maybe what’s most surprising about this journey is how systems thinking has affected the way I live. I’m someone who tends to overthink and worry about every little detail. But now, when I catch myself spiraling, I try to step back and ask: what is this part of a bigger system? Is this stress about one task actually connected to how I’m scheduling my day, or how much sleep I’ve gotten? It sounds small, but it’s made a huge difference. I don’t just “fix” my mood anymore—I try to understand what feeds into it. I apply that same logic to relationships, health, even budgeting. The ability to see connections, feedback, and flow has made me more thoughtful and less reactive. In a weird way, systems thinking has helped me become more human.</p>
        
              <p>To wrap this up, I believe that systems thinking is more than a tool—it’s a habit of mind. It challenges the way we see problems and gives us the courage to embrace complexity instead of avoiding it. Whether you’re designing a digital product, navigating a group project, or just trying to understand your own habits, systems thinking provides a deeper way to engage with the world. It doesn’t offer quick fixes. But it does offer clarity, depth, and a sense of interconnectedness that’s sorely needed in a time where everything feels fragmented. So yes, I started out thinking this was just some academic concept. But now, I see it as one of the most valuable perspectives I’ve ever learned. Thinking in loops instead of lines isn’t just helpful—it’s essential.</p>
            </section>
        
            <footer class="article-footer">
              <h3>Sources</h3>
              <p>Holt, B. (2019). <em>Systems Engineering Demystified</em>. Packt Publishing.</p>
              <p>Berman, S. J., & Korsten, P. (2021). The rise of the digital integrator. <em>IBM Institute for Business Value</em>. https://www.ibm.com/thought-leadership/institute-business-value</p>
              <p>Meadows, D. H. (2008). <em>Thinking in Systems: A Primer</em>. Chelsea Green Publishing.</p>
            </footer>
          </article>
<!-- Module 2.1 Blog Post Starts here -->
<article class="hidden">
   <header class="article-header">
      <h2>Human First: Designing for People, Not Just Products</h2>
     <p><em>By Nai</em></p>
   </header>
 
   <section>
      <p>In the world of digital innovation, it's easy to get swept up by technology. We celebrate breakthroughs in speed, automation, and scale—but often forget that the ultimate user is human. That’s why the philosophy of <strong>human-centered design</strong> (HCD) is not just a trend but a necessary foundation for effective user experiences. At its core, human-centered design focuses on crafting systems, interfaces, and products that prioritize users’ needs, abilities, emotions, and limitations. This approach goes beyond aesthetics and functionality. It requires deep empathy, awareness of perception and attention, and an ethical responsibility to make technology inclusive and intuitive.</p>
    
      <p>Human-centered design is defined by the International Organization for Standardization (ISO) in its standard <a href="https://www.iso.org/standard/77520.html" target="_blank">ISO 9241-210</a> as an approach that “enhances effectiveness and efficiency, improves human well-being, user satisfaction, accessibility and sustainability; and counteracts possible adverse effects of use on human health, safety and performance” (ISO, 2019). This model outlines six key principles, including understanding users, involving them throughout the design process, and evaluating solutions against real user needs. The ISO perspective is structured, focused on measurable outcomes, and rooted in usability engineering. In contrast, IDEO’s <a href="https://www.designkit.org/resources/1" target="_blank">Field Guide to Human-Centered Design</a> takes a more creative, flexible, and community-oriented approach. IDEO emphasizes storytelling, co-creation, and prototyping with empathy at the center. Their methodology encourages designers to walk in the shoes of users, explore open-ended ideas, and treat failure as a stepping stone.</p>
    
      <p>While both models value empathy, their perspectives diverge in formality and application. ISO promotes precision and repeatability, ideal for systems with high stakes like healthcare or finance. IDEO thrives in innovation contexts—designing community solutions, apps, or user journeys. Despite differences, they share a common mission: design with, not just for, people.</p>
    
      <p>One of the most powerful tools in human-centered design is understanding how people perceive and process visual information. Designers don’t just place buttons or headers arbitrarily—they use perception principles and visual hierarchy to guide attention, minimize confusion, and promote action. For example, a common online store layout positions the "Add to Cart" button in a bold, high-contrast color below the product image. This isn’t just a style choice—it reflects how our eyes scan the screen. According to Gestalt psychology, humans group related items and seek patterns. A proper visual hierarchy supports this by arranging content based on importance—larger, bolder elements signal priority while subtler ones fade to the background (Ware, 2021).</p>
    
      <p>Take Amazon’s checkout page: the primary "Place your order" button is large, yellow, and isolated from secondary actions. It grabs attention instantly. The hierarchy here is functional: it reduces friction, drives conversions, and prevents errors. Now contrast that with a poorly designed government site where crucial links are buried under unstructured text, making users hunt for basic services. That frustration isn't just annoying—it’s a breakdown of empathy in design.</p>
    
      <p>Understanding perception also means considering accessibility. Colorblind users, for instance, may not differentiate red error messages from green confirmations. A human-centered approach uses labels, icons, and contrasts that work across a wide range of visual abilities. It’s about inclusion as much as intuition.</p>
    
      <p>The importance of human-centered thinking becomes clearer when analyzed through four foundational UX laws: Jakob’s Law, Fitts’s Law, Hick’s Law, and Miller’s Law. These aren't just theoretical—they’re grounded in human cognition and behavior and serve as decision-making guides throughout the design process.</p>
    
      <p><strong>Jakob’s Law</strong> asserts that “users prefer your site to work the same way as all the other sites they already know” (Krug, 2014). In other words, familiarity breeds usability. When designing a banking app, for example, it’s wise to follow the convention of having a navigation bar at the bottom and a hamburger menu for more settings. This reduces the cognitive load and prevents users from feeling lost.</p>
    
      <p><strong>Fitts’s Law</strong> focuses on the time it takes to reach a target area, stating that the size of a target and its distance from the user affects how fast it can be accessed (Fitts, 1954). Think of the “Submit” button on a mobile form. If it’s small and crammed in the corner, users will fumble or mistap. Apple’s iOS interface follows this law religiously—important actions are large, well-spaced, and within easy reach.</p>
    
      <p><strong>Hick’s Law</strong> states that the more choices users have, the longer they take to decide (Hick & Hyman, 1952). This is crucial for onboarding flows, menus, and e-commerce navigation. A homepage bombarded with 20 categories overwhelms users. But if you cluster options into digestible chunks—like Netflix’s “Trending,” “Recommended,” and “New Releases”—you reduce decision time and increase satisfaction.</p>
    
      <p><strong>Miller’s Law</strong> highlights that humans can hold 7 ± 2 items in working memory at a time (Miller, 1956). This informs chunking strategies in interfaces. For instance, a dashboard with endless data points becomes unusable. But if metrics are grouped into "Sales," "Customer Feedback," and "Inventory"—users can process the information meaningfully.</p>
    
      <p>At the heart of all these laws is a single truth: people are not machines. We forget, get distracted, feel anxious, and make mistakes. A designer’s job is to anticipate that—and design around it. Human-centered design doesn't just optimize; it empathizes.</p>
    
      <p>Let’s look at a real-world example: the redesign of the New York City MetroCard vending machines. The old system was confusing—users had to choose between options like “Refill” or “New Card” before even seeing pricing. A redesign team applied Hick’s Law and reordered the flow. They started by asking users how much they wanted to spend or how many rides they needed. Then they clarified refill options later. This re-sequencing led to shorter transaction times and fewer abandoned purchases (Norman, 2013).</p>
    
      <p>Perception and empathy also shape digital interfaces through the lens of attention. Designers use attention cues like motion, spacing, and contrast to highlight what matters. But empathy extends further—it means considering emotional states. A user trying to report harassment on a platform might be scared or upset. A good UX pattern would streamline this path, avoid excessive steps, and offer supportive language.</p>
    
      <p>IDEO’s Field Guide reinforces this with stories of designers embedding themselves in communities—from rural farmers to hospital patients—to understand not just what users say, but what they feel and need. One example involved improving maternal health in Kenya. Designers discovered that women weren’t using clinics not because of poor access, but because of shame from male-dominated waiting rooms. The team responded by reorganizing spatial layouts to create private, women-centered spaces. Usage increased dramatically (IDEO.org, 2015).</p>
    
      <p>Human-centered design reminds us that every interaction—whether it’s tapping “Buy Now,” setting a reminder, or requesting help—is shaped by emotion, context, and cognition. Great design isn’t about pushing features; it’s about reducing friction, increasing joy, and fostering trust.</p>

      <p>One of the biggest challenges in design today is balancing innovation with familiarity. While creativity helps push boundaries, it’s also important to meet users where they are. For example, if a travel booking app introduces a brand-new way to select flights that’s too different from what people are used to, it might confuse or even frustrate them. Human-centered design helps solve this by reminding us that new ideas should enhance the user experience—not make it harder. This balance is why user testing and feedback are essential parts of the design process. Designers can’t just assume their solution works—they need to observe how real people interact with it, where they pause, what they ignore, and when they get stuck. These patterns tell a story about the user’s mental model, which guides how they expect a system to behave. If that model clashes with what’s been built, it leads to frustration. That’s why tools like heat maps, usability sessions, and A/B testing are so valuable. They turn feedback into insight and help shape decisions based on user behavior, not just guesses. Human-centered design isn’t just about making things look nice or work well—it’s about understanding people’s mental load, emotions, and habits. When designers take the time to explore how users think and feel, they build systems that are not only effective but emotionally intuitive. This can increase trust, brand loyalty, and satisfaction. Whether it’s a simple to-do list app or a complex healthcare portal, the principles remain the same: listen to users, test often, and remember that design is not about impressing users—it’s about empowering them.</p>
    
      <p>In conclusion, designing for people means much more than making things “look good.” It’s about building systems that reflect how humans think, behave, and feel. Whether through ISO’s structured process or IDEO’s empathetic immersion, human-centered design principles are vital in shaping technology that serves rather than frustrates. When we apply perception science, follow UX laws, and put empathy at the core, we move beyond products—and build experiences that feel human.</p>
    
      <footer>
        <h2>References</h2>
        <ul>
          <li>Fitts, P. M. (1954). <em>The information capacity of the human motor system in controlling the amplitude of movement</em>. Journal of Experimental Psychology, 47(6), 381–391. https://doi.org/10.1037/h0055392</li>
          <li>Hick, W. E., & Hyman, R. (1952). <em>The rate of gain of information</em>. Quarterly Journal of Experimental Psychology, 4(1), 11–26. https://doi.org/10.1080/17470215208416600</li>
          <li>IDEO.org. (2015). <em>The Field Guide to Human-Centered Design</em>. https://www.designkit.org/resources/1</li>
          <li>International Organization for Standardization. (2019). <em>ISO 9241-210:2019 Ergonomics of human-system interaction — Part 210</em>. https://www.iso.org/standard/77520.html</li>
          <li>Krug, S. (2014). <em>Don't make me think, revisited: A common sense approach to web usability</em> (3rd ed.). New Riders.</li>
          <li>Miller, G. A. (1956). <em>The magical number seven, plus or minus two: Some limits on our capacity for processing information</em>. Psychological Review, 63(2), 81–97. https://doi.org/10.1037/h0043158</li>
          <li>Norman, D. A. (2013). <em>The design of everyday things</em> (Revised & expanded edition). Basic Books.</li>
          <li>Ware, C. (2021). <em>Information visualization: Perception for design</em> (4th ed.). Morgan Kaufmann.</li>
        </ul>
<!-- Link to next page -->
<p style="text-align: right; margin-top: 20px;">
   <a href="module2.2.html" style="font-family: Arial, sans-serif; font-size: 14px; color: grey; text-decoration: underline;">
     → Continue to Module 2.2: Designing for Empathy
   </a>
 </p>
</footer>
      </footer>
    </article>
     <!-- Module 2.2 Blog Post Starts here -->
  <article>
    <header class="article-header">
       <h2>Module 2.2 Blog Post</h2>
   <header>
     <h1>Support User Thinking: Why Usability Starts in the Mind</h1>
   </header>
   <article>
     <p>When people interact with a digital system—whether it's an app, a website, or a software platform—they don’t stop and think about all the processes going on in their brain. But behind every tap, swipe, or click is a complex set of mental functions working together to understand, predict, and respond to the system’s behavior. Good design doesn’t just look nice—it supports the way people think. This means that designers have to understand human memory, habits, and the shortcuts our brains take to save time and energy. If the design doesn't support these natural tendencies, it forces users to do more thinking than they should, which results in frustration, confusion, and errors.</p>
 
     <p>One of the most important things to consider when designing for usability is memory. Human memory has its limitations, especially short-term memory, which can only hold a small amount of information at a time. George Miller’s research from the 1950s (Miller, 1956) suggested that people can hold about seven items in their working memory—give or take two. That might not seem like much, but in a digital environment, it matters a lot. Think about when you go to a website and see 12 different menu options or a long form with too many steps. Your brain starts to feel overloaded, and the experience becomes tiring. This is where the idea of cognitive load comes in. If a user has to remember too much or figure out too many things on their own, they become mentally exhausted.</p>
 
     <p>Another way memory plays a role in usability is through what we call mental models. A mental model is a user’s internal idea of how a system is supposed to work. This model is built from past experiences, intuition, and learned behavior. For example, when someone sees a shopping cart icon, they automatically know it’s where their selected items go. Or when they click on a logo in the top-left corner of a page, they expect it to take them back to the homepage. When designers stick to these mental models, users feel comfortable and confident. But when designs break these expectations—for example, placing navigation buttons in random spots or using unclear symbols—users feel confused and lost (Johnson, 2020).</p>
 
     <img src="mo 2.2 photos/mo 2.2 2.png" alt="Illustration of mental processing and interface" style="width:100%; margin-top: 20px;">
     <p><em>Figure 1: Visualizing how mental models shape digital interaction, (<a href="https://google.com/photos/kcA-c3f_3FE" target="_blank">source</a>).</em></p>
 
     <p>Consistency is one of the best ways to support both memory and mental models. If users see the same layouts, fonts, icons, and terminology across a system, they don’t have to learn how to use it all over again each time. This reduces cognitive load and makes the system feel more predictable. As Don Norman (2013) explains in The Design of Everyday Things, good design builds trust by being reliable and easy to predict. Most people don’t want to “figure out” how to use something—they want it to just make sense. That’s why most social media apps put the notification bell, settings gear, and profile icon in similar places. When everything looks familiar, the brain can relax.</p>
 
     <img src="mo 2.2 photos/Mo 2.2 1.jpeg" alt="Consistent UI design across apps" style="width:100%; margin-top: 20px;">
     <p><em>Figure 2: Familiar UI elements reduce mental strain  (<a href="https://google.com/photos/Bg0Geue-c8Q" target="_blank">source</a>).</em></p>
 
     <p>Feedback is another crucial element of usable design. Every time a user takes an action, they expect some kind of response. Whether it's a subtle vibration, a loading spinner, or a confirmation message, users need to know that the system received their input. Without feedback, they’re left wondering if their action was successful—or if the system is broken. In Designing with the Mind in Mind, Jeff Johnson (2020) emphasizes the importance of perceptual causality: the idea that users need a fast, clear signal that something is happening. For example, if a person taps a “Submit” button and nothing happens, they may tap it again…and again…which can lead to duplicate submissions or errors. I’ve personally experienced this while submitting a university form online. The page didn’t change or give any feedback, so I clicked “Submit” three more times, and the system processed it four times in total! A simple visual cue could have prevented that. </p>
 
     <p>On the flip side, poor design can increase cognitive load unnecessarily. I remember trying to help a friend sign up for financial aid through a government portal. The login page was a mess—the fields were unlabeled, the error messages were vague, and even the “Help” link didn’t provide helpful information. It took multiple attempts and a lot of guessing to finally get it right. The design failed because it didn’t align with the way people think or behave. Instead of helping the user, it forced them to do more mental work. This is a perfect example of what Tesler’s Law warns against. Tesler’s Law states that every system has an inherent level of complexity—someone has to deal with it. If designers don’t handle it, the burden falls on users (Tesler, as cited in Norman, 2013). Good systems hide that complexity through thoughtful design, automation, and sensible defaults.</p>
 
     <p>Let’s look at a real-world example. Many food delivery apps allow users to save their address. Once saved, it becomes the default for future orders. This saves time and reduces friction. Now imagine if every time you placed an order, the app asked you to re-enter your full address from scratch. That’s not just annoying—it’s an example of the system offloading complexity onto the user. By saving that data and applying it automatically, the system does the thinking for the user, following the principle of minimizing user input.</p>
 
     <p>Another principle from Johnson’s book that supports usability is the Principle of Proximity—the idea that elements placed close together are perceived to be related. This is why most websites group navigation buttons together and place form labels next to their input fields. It sounds basic, but it has a huge impact. If the “Delete” and “Save” buttons are far apart, users are less likely to hit the wrong one. But if they’re right next to each other and look the same, mistakes happen. The principle of proximity helps prevent that.</p>
 
     <p>Design also needs to account for how people learn through repetition and habit. Over time, users develop routines for how they use certain systems. If a software update suddenly moves a familiar button to a new location or changes its icon, users will be frustrated—even if the new version is “better.” That’s because habits are hard to break, and change creates a new learning curve. For example, when Instagram moved the post button, many users complained not because the new placement was worse, but because it broke their habits. If users are forced to re-learn things too often, they may stop using the product altogether.</p>
 
     <p>This ties into another powerful concept: heuristics, or mental shortcuts. These are rules of thumb the brain uses to make quick decisions. For example, if something looks like a button, we expect it to be clickable. If it has a drop shadow or changes color when we hover, we assume it can be pressed. These mental shortcuts help us interact with systems quickly and efficiently. But when design ignores or breaks these rules, users get frustrated. For instance, a flat image that looks like a button but doesn’t respond can mislead users and break their trust.</p>
 
     <p>Another great example is the search function on websites. Users expect a magnifying glass icon to represent search. If a designer replaces that icon with something abstract or puts the search bar in an unusual place, users might not find it at all. That’s why conventions exist—they help reduce the amount of thinking users need to do. Following these conventions isn’t lazy—it’s respectful of users’ time and mental energy.</p>
 
     <p>Another often overlooked but vital aspect of supporting user thinking is error prevention and recovery. No matter how intuitive a system is, users will still make mistakes. A well-designed system doesn’t just tell users they made an error—it helps them fix it quickly and painlessly. According to the Nielsen Norman Group (n.d.), effective design includes not only clear error messages but also suggestions for correction.</p>
 
     <img src="mo 2.2 photos/mp 2.2 3.png" alt="User interface showing helpful error message" style="width:100%; margin-top: 20px;">
     <p><em>Figure 3: Helpful feedback builds user trust (<a href="https://google/photos/bcbf1c2c-1b44-40b7-9dd3-cfd928024d83" target="_blank">source</a>).</em></p>

     <p> Design isn’t just about making things look good—it’s about making things work well for the people using them. That includes clear navigation, simple language, readable fonts, and mobile-friendly layouts. When users don’t have to stop and think about how to use a system, they can focus on their goals. When systems support how we think, remember, and behave, we can be more productive and less frustrated.</p>
 
     <p>In conclusion, supporting user thinking means designing with the brain in mind. Usability is about reducing the mental work users have to do. That means designing systems that match users’ mental models, minimizing memory load, providing clear feedback, and following consistent patterns. Good design doesn’t just help people—it respects them. By applying principles like Tesler’s Law, perceptual causality, proximity, and memory limits, we can build systems that are not only functional but truly user-friendly. Whether you're designing a website, an app, or any digital tool, always ask yourself: “Am I making this easier for the user—or harder?” Because the best systems aren’t just usable—they’re invisible.</p>
   </article>
 
   <footer>
     <h2>References</h2>
     <ul>
       <li>Johnson, J. (2020). <em>Designing with the mind in mind: Simple guide to understanding user interface design guidelines</em> (3rd ed.). Morgan Kaufmann.</li>
       <li>Miller, G. A. (1956). The magical number seven, plus or minus two: Some limits on our capacity for processing information. <em>Psychological Review, 63</em>(2), 81–97. https://doi.org/10.1037/h0043158</li>
       <li>Norman, D. A. (2013). <em>The design of everyday things</em> (Revised and expanded ed.). Basic Books.</li>
       <li>Nielsen Norman Group. (n.d.). <em>10 usability heuristics for user interface design</em>. https://www.nngroup.com/articles/ten-usability-heuristics/</li>
       <li>Usability.gov. (n.d.). <em>User interface design basics</em>. https://www.usability.gov/what-and-why/user-interface-design.html</li>
     </ul>
   </footer>
 </body>
 </html>
 <!-- Module 2.3 Blog Post Starts here -->

 <!-- Module 3.1 Blog Post Starts here -->

 <!-- Module 3.2 Blog Post Starts here -->

</main>
<!-- Page Footer  -->
<footer class="page-footer">
<p>Copyright &copy; 2025</p>
</footer>
</body>
</html>