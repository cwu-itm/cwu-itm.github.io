<!DOCTYPE html>
<html lang="en">
   <head>
      <meta charset="UTF-8">
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      <link href="css/styles.css" rel="stylesheet">
      <title>Cecelia Andetsen | Portfolio</title>
   </head>
   <body>
<!-- Page Header  -->
      <header class="page-header">
         <h1>Portfolio</h1>
      </header>
<!-- Main Content Area  -->
      <main>
         <!-- Module 1.1 Blog Post Starts Here-->
         <article>
            <header class="article-header">
               <h2>Module 1.1 Blog Post</h2>
            </header>
            <h3>Systems Thinking for Digital Environments</h3>
            <p>Holt (2022) defines systems thinking as a way to make clear the relationships, interfaces, and interaction of component systems, instead of seeing them in isolation. In summary, systems thinking is the ability to look at the large system in general rather than at the smaller components in isolation. Focus is on the interplay of each part of the system; the effects of each one on the whole. In modern systems, especially technologically, it is relatively uncommon for a system to be simple. Websites, apps, etc. are multilayered pieces of a bigger whole that must all work collaboratively during that process. As a result, systems thinking has developed in such a manner that the design of digitally-based systems becomes a more robust mechanism, as it is essential that things work seamlessly, simultaneously (Holt, 2022). </p>
            <h3>In my own words</h3>
            <p>Systems thinking to me is like walking away to see how all the pieces of the puzzle fit together before taking a step forward and trying to fix or build something different. Not simply one thing at a time, but the relationship between these things. When a thing is broken down on the basis of components, it means knowing how they depend on each other and how one modification might affect the other components. Holt (2022) emphasizes that systems involve components which continuously influence and respond to one another which are just as important as the system's individual components. It is the combination of the problems: multiple pieces not in unison, not one failure,  that is the cause of a lot of failures. For example, a webpage may look great from the outside and load, but if it can’t handle traffic or connect correctly to a database, the system will break down. Systems thinking works in contrast to the approach of ignoring these relationships in the early stages.</p>
            <h3>Systems vs Linear Thinking</h3>
            <p> Linear thinking considers the task in its own parts, as each part is self-created. It is the integration point at the end of the process when one looks inwards. To illustrate, the first step is to construct a part, then a more or less a third part, then another. Even for easy predictable issues/projects, though, this strategy fails at times with growing complexity. One of the big distinctions between systems thinking and linear thinking is the timing. As noted, integration in linear thinking cannot be emphasized until the majority of components are created. In systems thinking, integration becomes the goal from the start. Without developing the parts, designers only contemplate how components will link together. The focus is another thing that's different; linear thinking focuses on tasks and components, while systems thinking is more closely related to relationships and interactions. A component might work well on its own, but a component without proper interactions can be inefficient and cause failures. Complexity and poor communication, according to Holt (2022), are some of the reasons why systems fail. Linear thinking often aggravates these problems: teams will work on individual parts separately, not fully realizing how their hard work affects the whole system. When everything is built out, remediating problems is more complicated and expensive than ever.</p>
            <h3>Why Linear Thinking in Complex Systems can be an Issue</h3>
            <p>Linear thinking is a thinking problem of the system-as-cause-and-effect type that assumes system behaviour is cause and effect (i.e., system behavior works cause and effect for everything) which does not always occur. The majority of contemporary systems involve feedback loops and a system's behavior evolves over time. Meadows (2008) has observed that complexity can ineluctably result from the unpredictability of systems, as activities in one part can have an adverse effect on the other. It doesn’t take the form of linear thinking because of its disconnected point of view on problems. For example, if a new feature is introduced in an app that would help the user, but may increase server costs or add a security concern too, that’s an example of adding something new but at the same time it will also make your app even more expensive.</p>
            <h3>Model Based Approach</h3>
            <p>Systems are becoming increasingly intricate, and to think system-based is not necessarily the best way. Designers themselves require an understanding to help structure knowledge and to see how it all fits together. This is where model based systems engineering (MBSE) comes in handy (INCOSE, 2022). Holt (2022) adds that this method of model is that the model becomes the main source of information about the system. Everything is structured together in a neat, orderly manner, rather than scattered documents, notes, or diagrams. This is the framework which indicates what the system should be capable of, how it is built and how different components come together; the model provides a general picture of the system. A model is a mapping of the system and it provides designers insights into how everything interconnects prior to the system getting built out so that all is linked between everything else. This helps detect issues sooner and the long-term effects of changes. The thing that is great about this method is there is less confusion. Different teams using different documents can lead to inconsistent information. A feature may be described differently in one file and differently in another. Using a shared model keeps everyone on the same page. That is how models ease complexity for you. For it to be effective, using a model-based method is good for communication. Developers, designers, managers, as well as security teams can reference the same model in the system. When something changes, the model is updated and a consequence of change can be detected throughout the system.</p>
            <h3>Wrapping things up</h3>
            <p>Systems thinking, in the end, is just intentional technology design. It encourages not thinking of each individual element as a task, but thinking of how everything makes contact and how each relationship changes the product. The digital world is built on devices interacting with users, networks, data and other systems. That kind of thinking is far more realistic than a simplistic linear approach. A model-based methodology facilitates this goal because it offers designers a framework for information storage, data analysis, and preparation for change well in advance of challenges themselves (Holt, 2022). As technology moves to this stage, designing systems with a global lens is certainly better for technology but it is also more crucial than ever if systems are to deliver on promises and capabilities out in the wild. What makes this approach so useful is the rapid pace with which digital systems change. They are always adding features, updates and new user expectations. Without systems thinking, such transitions usually come with unforeseen side effects including slowdowns, bugs, security compromises, or compromised integrations. Small decisions can, however, add up if designers fail to consider the broader system-wide effects of updates. Systems thinking is meant to avoid this altogether, to make real the connection between what we think in the short term versus what we think in the long term. A model approach would support that mindset as it would allow designers to see and trace those relationships over time. If team members are not forced to use memory or occasional scraps of fragmented documentation, they can use the model to better know how different parts are connected and where there are risks. And when systems must grow, interface with new technologies or need to adapt to new requirements, understanding this needs to be more emphasized. Rather than rebuilding from scratch or throwing away an issue as soon as it arrives, a designer can adopt a design tweak that leaves room for stability. Systems thinking takes into account reliability, clarity, and long-term success, not just speed or convenience. In digital systems  that are all interlocking, ignoring the fundamentals is almost as bad as the next problem. Systems thinking, facilitated through the model-based approach which allows for the design of technologies that work not just after launch, but over time as developed and normalized by others into their everyday lives.</p>
            <footer class="article-footer">
                <h3>Sources:</h3>
                <ol>
                    <li>Holt, J. (2022). Systems engineering demystified: Apply modern, model-based systems engineering techniques to build complex systems (2nd ed.). Packt Publishing.</li>
                    <li>Meadows, D. H. (2008). Thinking in systems: A primer. Chelsea Green Publishing.</li>
                    <li>International Council on Systems Engineering (INCOSE). (2022). 
INCOSE vision 2035: A world in motion. 
https://www.incose.org</li>
                  </ol>
            </footer>
         </article>

         <!-- Module 1.2 Blog Post Starts here -->
          <article>

  <header class="article-header">
    <h2>Module 1.2 Blog Post</h2>
  </header>

  <h3>Systems Life Cycle Models in Digital Environments</h3>

  <p>
    When thinking about technology, people’s minds are usually filled with the thought of the end product. This could be an app, a website, a system, etc., but typically it is something that will already work. What some people forget to think about is everything that happens either before or after the system’s rollout. Your digital systems don’t get constructed once and never evolve. They have a process that includes processes all the way from starting up all the way up to the completion of the life cycle of the system. Understanding what life cycle is, then, also matters because it describes how systems are designed, built and maintained, all the way to ultimately being replaced or altered.
  </p>

  <p>
    This process is then divided up under a life-cycle model of systems engineering. It gives the team a way to see what stage a system is at, what it should be as it moves further. Holt (2022) clarifies that life cycle thinking encourages designers to not only target what exactly is the system, but how such a system should be maintained and revised. Especially in the digital world where technology never stays fairly static and user needs always keep going up.
  </p>

  <p>
    At a glance, the systems life cycle is a sequence of stages including problem identification, problem solving, design, building, validation, deployment, and support of the system. At some point systems become old and need to be replaced. A good strategy that will prevent jumping to conclusions or designing poorly is considering every one of these phases in-depth on a pre-programmatic timeline. Rather than reacting to issues in the moment, teams can prepare for issues as they surface.
  </p>

  <h3>Linear Life Cycle Model</h3>

  <p>
    One of the more conventional approaches to the life cycle is a linear model. All is step by step to the end of the life cycle. Requirements are gathered in the very first place. That is how it is, the system is designed, built, tested, and deployed. Teams rarely go back and modify a stage after the point where the stage has ended, and usually once they have.
  </p>

  <p>
    This approach tends to work really well for small projects like these--or systems where requirements are established from the beginning. But linear models are seldom viable for the present digital systems we use. In fact, the technology changes so fast, something is very, very unlikely to hold once a project has been established as a whole. The late-in-development problem can be painful, expensive. This inflexibility can allow outdated or inefficient systems to become outdated soon on opening in the market (Holt, 2022).
  </p>

  <h3>Iterative Life Cycle Model</h3>

  <p>
    The majority of teams, therefore, follow iterative life cycle models. Systems are built in cycles in repeating iterations. Rather than taking everything to build at once, teams develop, build, test and iterate smaller parts of the system over weeks (or a year). All design iterations are tested, developed, and validated with the help of feedback, experimentation or insight from feedback, testing, or new data.
  </p>

  <p>
    Should a given feature be requested or a bug be cited by users, the group can do the work and fix the software in the next iteration. It also involves good communication and organization, even though it is far more flexible. Consistent change and variation (if goals are not clear) could bog down the project or make them unclear.
  </p>

  <h3>Incremental Life Cycle Model</h3>

  <p>
    An approach that was widely considered, however, is the incremental life cycle approach. The approach to incremental development is trying to do smaller chunks of a system where it will end up being usable, in smaller parts, little by little. Teams release system components in small doses rather than tearing it out of a box and waiting for everything to be finalized. Provide additional functionality wherever you can, providing additional functionality up until full system completion.
  </p>

  <p>
    This works for users, If they get the system sooner it works better, and developers are continually tweaking the product. Incremental models of growth are particularly useful in digital contexts where systems need to incrementally progress over time. And an app might develop modest features at launch, then incrementally add new features to it as development becomes faster, especially through updates.
  </p>

  <p>
    As Holt (2022) has written, doing this lowers risk because it is easier to resolve issues by using just one increment, without compromising the overall system. And systems thinking is favored because every subsequent piece has to mesh well with what’s already in place.
  </p>

  <h3>Why Life Cycle Models Matter</h3>

  <p>
    There aren’t some right model of life cycle for all cases. Linear models do provide a shape, but they are inflexible. Innovative, iterative models call for strong coordination: Learnable and adaptable. Incremental approaches are at the middleground between progress and adaptation but require planning in details. In practice and in many real-life projects, teams leverage parts of several models to suit their individual needs.
  </p>

  <p>
    Life cycle models are important in the case of digital systems, because these systems are rarely stable. Websites and apps are not static, and need upgrades and security patches and performance improvements and new features. They could bring unexpected problems to bear because there is no clear life cycle plan for each update.
  </p>

  <p>
    Feedback loops and components operating in a different way tend to produce unpredictable behavior in systems (Meadows, 2008). A small adjustment in one area starts troubles in another. Inventing the life cycle reduces these kinds of team issues through long-term thinking.
  </p>

  <p>
    Designers do not only look forward to the quick-fixes, instead, they consider how such changes may have an impact on the system in the longer term. This leads to better, resilient systems. It is also a cost reduction: systems that were easier to maintain in the past are inherently less likely to depend on a flood of emergency remedies later in the year.
  </p>

  <p>
    According to the International Council on Systems Engineering (INCOSE), to design systems prepared for the future, there has to be life cycle consciousness (INCOSE, 2018). Failures will quickly proliferate as digital systems grow more interconnected. Careful, deliberately-built life cycle plans teams assist by a carefully executed life cycle plans help them through this diversity, getting prepared rather than getting caught in the net-jumps before or after that happens.
  </p>

  <p>
    In preparation, they are ready to get ready for change yet are not overwhelmed by it. Life cycle models dictate how users experience systems in everyday technology that they are in touch with every day. The concept of the incremental and iterative life cycle is also being used with regular updates, new functions, and improvements. In other words, its application in everyday business processes.
  </p>

  <p>
    When they’re fine-tuned, and these processes are the go-to, systems are good, seem smooth and reliable. When they aren’t, users get bugs, crashes or broken features.
  </p>

  <p>
    Last but not least, systems life cycle models advocate for planning of technology that is intentional in nature. They can offer designers a reminder that building a system is not about having it work at a single moment, but over time. Digital systems function in a dynamic and fluid environment, so failing to realize this fact virtually guarantees future issues.
  </p>

  <p>
    Implementing a life cycle and systems thinking when designing solutions also facilitates design systems that are more adaptable, more reliable, of which the first is a good example. At a time when the world of technology and its applications is evolving at such a fast pace, life cycle thinking is more than helpful, it is necessary for a system to succeed practically speaking.
  </p>

  <footer class="article-footer">
    <h3>Sources</h3>
    <ol>
      <li>Holt, J. (2022). <em>Systems engineering demystified: Apply the principles of systems engineering to develop complex systems</em> (2nd ed.). Packt Publishing.</li>
      <li>Meadows, D. H. (2008). <em>Thinking in systems: A primer</em>. Chelsea Green Publishing.</li>
      <li>International Council on Systems Engineering (INCOSE). (2018). <em>INCOSE Vision 2035: A world in motion</em>. https://www.incose.org</li>
    </ol>
  </footer>

</article>


         <!-- Module 2.1 Blog Post Starts here -->
          <article>
          <header class="article-header">
          <h2>Module 2.1 Blog Post</h2>
          <h3>Human First</h3>
          </header>

          <p>When we talk about good design, we typically mean that something looks nice. The layouts are clean, the app doesn’t look outdated, the scheme is aesthetically pleasing, and so on. In reality, good design stretches far deeper than that. A lot of the time, the design most appealing to people is not the coolest looking design, but feels easy; you don't have to think too much when using it, you don't get confused or feel like you're fumbling around. That is more or less the essence of human-centered design.</p>

          <h3>Human-centered Design</h3>

          <p>Human-centered design means, in other words, that the systems are built around actual people, and not based on what’s trendy or what the system is supposed to be like by means of the designer’s thinking. It’s the construction of something that aligns with how people actually act. People become distracted, they skim, they don’t read everything, and they make decisions fast. If a system doesn’t match how people behave naturally, the system isn’t really usable, even if it is doing the job technically.</p>

          <p>ISO 9241-210 describes human-centered design as an approach that involves understanding user needs and how they may interact with systems during design (International Organization for Standardization [ISO], 2019). One of the things I love about this is that it reminds you that design is not simply what the user sees. It’s about how users engage with the system. Designing for people is about building for people, who are not always perfect users; they inevitably make mistakes. It requires a design which fits the needs of the user as an individual without unlimited time and a lot of energy. Many people that use systems are multitasking. They’re on their phone, rushing, etc., and at the end of the day, they just want to get their tasks done without unnecessary difficulties.</p>

          <p>Something this module made completely clear was that human-centered design always begins early, and probably a lot earlier than most people would assume. This is not just add-on material when the system is already built. It's what you design during early stages that dictates how easy your system will be to use. By designing something without regard for perception and attention, the system can rapidly turn into shambles. Even when the developers have done everything right, the user could still be overwhelmed by or be confused by this interface.</p>

          <h3>ISO vs. IDEO</h3>

          <p>The IDEO Field Guide is still human-centered design but is definitely more hands-on and real life than ISO. ISO comes off as more of a framework or a process. IDEO feels like you’re really studying people. It emphasizes empathy and understanding a user's experiences, not only what they say a user wants (IDEO.org, 2015). The difference matters: sometimes, until someone else is in the wrong spot, they don't even know whether something matters at all. Observing real users interact with a design teaches you something different: it can bring to light problems you would never see if only design based on guesses or assumptions. If we had to compare them I'd say ISO 9241-210 is basically a systematic plan for ensuring that human-centered design happens, and IDEO is kind of just the perspective and all this equipment that makes design feel more human. ISO ensures you don’t go off the rails.</p>

          <h3>Perception and Visual Hierarchy</h3>

          <p>The perception and visual hierarchy bit was also super relevant. People are not looking at a screen in the manner designers want them to. Much of the time, we scan, and our eyes go on to what looks most important. That's why the arrangement of information on a page is so important to us. Visual hierarchy tells your brain what to look at first. If a website is shown with 10 things of the same size on the same font, same color, uniform type of font usage and style on the same page, it can be hard to figure out how to start. It’d seem more like a wall of information than anything else. That’s when users begin to skip over things or click the wrong thing. If the main button disappears into the background, no one will seem to notice that at all. They’ll hesitate and question too much, or they’ll just exit. One of these is a checkout screen. It feels stressful if someone is trying to purchase something and there are a bunch of popups, random ads, a million little fields. If the checkout is nice and the main action button pops up, the user tends to feel more secure. That’s design and usability in a nutshell, it’s much bigger than aesthetics. Understanding how attention works will allow a designer to simply make the interface that little bit simpler for the user without throwing a ton of bells and whistles. It’s literally a matter of making things clearer. Easier to read on layouts, easier on labels, less on clutter, which gives the user a sense that they know what they are doing.</p>

          <h3>UX Laws</h3>

          <p>That concept also ties to Jakob’s Law. Jakob’s Law essentially states the users expect that a website or app will behave similar to other web and apps they are familiar with, because they are accustomed to using those tools (Krug, 2014). When people open their websites, they don't want to learn a brand new look and feel, every time they open the menu. That is why most apps have similar icons and layouts. People know those patterns, and that knowledge makes things faster. When designers pull too hard to be “different,” it can hurt the user experience. A site may look unique, but if a user cannot find the menu, cannot find the search bar, and doesn’t understand the icons then what is needed to dig through them quickly becomes annoying.</p>

          <p>Designing for people means respecting people’s existing thought patterns and expectations. Fitts’s Law also connects very directly with usability. Fitts’s Law essentially states that the easier a target is to hit, the quicker the user can interact with it. If it is small or very far away, the time to click it takes longer (Interaction Design Foundation, n.d.). You can see this in real life all day, every day. Just as on mobile when buttons are very small, people just get the wrong click all the time. Another example is the close button on a popup being super small, squashed in a corner. That’s not an accident, and it is something that users find daunting and frustrating. If designers do design for people, they should design the buttons for the important stuff to be easy to hit, and provide enough space between clickable objects. They need to ensure the user is not fighting the interface just to do something simple. The design should enable movement of the user, not penalize them for having normal hands.</p>

          <p>Hick’s Law states that the more options you provide a person, the longer they take to make the decision. Too many choices have the potential to leave individuals feeling overwhelmed (Interaction Design Foundation, n.d.). I can relate to this and this seems to happen all the time online. Even simple things like setting menus can be preposterous. You will be forced to choose among fifty options, half of which you don’t even understand the meaning. The users then either pick randomly, or leave everything on default because they aren’t ready for it. Good design is not just about adding features. If the goals for a user are not difficult to achieve, the design should reduce choices. People lose interest if they’re given too many choices at once, and that's when mistakes tend to happen. Miller’s Law ties into this too. Miller’s Law is the concept that people retain only so many things in their working memory at a single time. Basically, humans can only contain so much information in their head at a time (Interaction Design Foundation, n.d.). A design that bombards users with too much information makes it more difficult to process. The user begins forgetting what they read and what the goal of their work was and also becomes more agitated. This is why breaking information into chunks helps as well as why a simpler interface might seem better than a more complex one by design. Even if both platforms are doing the same thing, the one that upholds the principles of holding on to the human mind and memory, appears to be user friendly and more accessible will be preferred.</p>

          <h3>Empathy</h3>

          <p>Another aspect we’ve started covering in designing for people is empathy, which to be honest is the most important part of it. Empathy isn’t about being nice alone, which is to say, it is about realizing that users are emotion-bound people who have limits. When stressed or time-pressed, a system can either help them or just make things ten times worse. IDEO discusses empathy a lot and learning from the real users themselves, not just assumptions from the database (IDEO.org, 2015). That is why it’s important: The designer is not the user. The designer may get the system right exactly because they designed it but the person is seeing it for the first time. A human-centered design respects that premise and supports the user rather than expecting that individual to “figure it out.”</p>

          <p>I also think empathy appears in little design details; things like explicit error messages, confirmation prompts, helpful labels or allowing people to undo things. Those elements increase a sense of safety for users of the system and reduce frustration.</p>

          <h3>Wrapping Things Up</h3>

          <p>All in all, this module really brought home the idea that human-centered design is not some fancy design trend. It’s a mindset and a process that enables systems to be simpler, more usable, in real life. ISO 9241-210 gives a systematic method for involving users and assessing designs through the process (ISO, 2019). IDEO adds the empathy and observation element, which helps designers really see users as people (IDEO.org, 2015). Perception and attention matter, as users fail to process information perfectly, and so visual hierarchy makes a difference in what they see and what they miss. UX laws such as Jakob’s, Fitts’s, Hick’s, and Miller’s also help explain why some designs seem smooth and others are frustrating to see playing into. So when we say ‘design for people’, we mean ‘design for normal human behavior. People skim, people forget, people get overwhelmed, and make mistakes. Therefore, the design of  the system should reflect that. If the system is constructed to align with those realities, it seems easier and flows more naturally. And if it’s not such, the system could still work, but it won’t seem like it was designed for people.</p>


          <footer class="article-footer">
    <h3>Sources</h3>
    <ol>
      <li>
        IDEO.org. (2015). <em>The field guide to human-centered design</em> (1st ed.). IDEO.org.
        <a href="https://www.designkit.org/resources/1">https://www.designkit.org/resources/1</a>
      </li>
      <li>
        Interaction Design Foundation. (n.d.). <em>UX design laws</em>.
        <a href="https://www.interaction-design.org/literature/topics/ux-design">https://www.interaction-design.org/literature/topics/ux-design</a>
      </li>
      <li>
        International Organization for Standardization. (2019). <em>ISO 9241-210:2019 ergonomics of human-system interaction—Part 210: Human-centred design for interactive systems</em>.
        <a href="https://www.iso.org/standard/77520.html">https://www.iso.org/standard/77520.html</a>
      </li>
      <li>
        Krug, S. (2014). <em>Don’t make me think, revisited: A common sense approach to web usability</em> (3rd ed.). New Riders.
      </li>
    </ol>
  </footer>
</article>

         <!-- Module 2.2 Blog Post Starts here -->
          <article>
          <header class="article-header">
          <h2>Module 2.2 Blog Post</h2>
          <h3>Support User Thinking</h3>
          </header>

          <p>In exploring human-centered design, it has become very clear to me that usability is deeper than what users see on a screen. Rather, it is centered around the level of thinking, remembering, and effort they must put in when using the system. You can create a system that looks clean and modern, while still being frustrating for users if it involves forced thinking or requires the user to remember too much. Good design takes into account how people intuitively understand and interact with technology.</p>

          <figure>
          <img src="images/notes.jpg" alt="Notebook and computer setup representing memory and external tools" style="height:400px; width:auto;">
          <figcaption>
          Photo by Kevin Canlas on Unsplash
          </figcaption>
          </figure>

          <h3>Memory & Mental Models</h3>

          <p>One of the major ideas from the readings is that human thinking is not just in our heads. Much of what we think is empowered by what tools exist around us. Writing things down, using reminders or leaning onto digital systems to help remember and organize information is something people do. This is sometimes called distributed cognition, where you allow your thinking to spread out to external tools instead of having everything in your mind. Well-designed digital systems enable that process and make users better agents in it. Badly designed ones add extra cognitive labor and frustration (Johnson, 2020).</p>

          <p>Memory is one of the big factors in how people interact with systems. People have short working memory, and struggle to hold too much all at once. A system that wants users to remember steps, settings, or instructions becomes harder to use. Systems are not meant to display data at random, but on sight so that the user uses perception, rather than memory, to guide their choices. Johnson points out that users should not need to remember what can be said to them from the system, because that adds to cognitive load unnecessarily (Johnson, 2020).</p>

          <p>Mental models influence the interaction behavior of users with the system as well. A mental model basically means an individual’s sense of how something works. These models are constructed by users from their experiences with similar systems in the past. If a system follows the model that they’ve used before, the system feels more user-friendly. But if it acts differently, users need to stop and figure things out that take effort and attention. Designing for the familiar is the best practice, because rather than making a user learn a pattern from scratch, it lets them rely on what they already know and doesn’t constantly teach them unfamiliar behavior.</p>

          <h3>Cognitive Load</h3>

          <figure>
            <img src="images/phone.jpg" alt="Person using a phone interface" style="height:400px; width:auto;">
            <figcaption>
            Photo by SumUp on Unsplash
            </figcaption>
          </figure>

          <p>Cognitive load is the amount of mental effort involved in using an item. When that kind of effort is too much, users end up confused, overwhelmed and frustrated. Poor design is a result of a system requiring a lot of attention or memory from the user. The readings gave several examples, one being when a website asks for a “member ID,” but the user knows only his username, he has to pause and figure out what the system means, which takes their mind away from their real goal. They are focusing on decoding the interface, not on completing an assignment. Users should not have to jump through hoops in the name of doing simple stuff (Johnson, 2020).</p>

          <p>A second example is in systems where users are expected to diagnose problems themselves. If a checkout process collapses and returns an error message then they’ll be left to puzzle over the problem. This sort of thing requires a certain level of technical knowledge and additional effort that users shouldn’t have to be burned with. I myself have faced this issue when using Canvas. When attempting to upload certain assignments or embedded media in discussion posts there have been several instances in which an error message will be displayed without explanation or support. Thankfully, I have enough basic knowledge to troubleshoot myself, but when this has happened it has still disrupted my workflow and taken time away from additional tasks I needed to do in order to complete assignments. The system ideally should accommodate that complexity and be clear enough to guide its users.</p>

          <p>Designers need to minimize the focus that users place on the system in order they get to do what they really want to do (Krug, 2014). That’s something I can say happens quite often in settings menus from my experience. Some apps have so many options that it’s hard to know what to change. You are left guessing or doing it all on default because it is too much to digest. That, of course, is a textbook example of too much cognitive load. If the system simplified the options or grouped them better, it would be easier to navigate.</p>

          <h3>Tesler's Law</h3>

          <p>Tesler’s Law explains that every system has some level of complexity that can’t be removed (Yablonski, 2024). The complexity exists somewhere; it either sits there with the user, or it gets processed by the system and the designers. Good design tries to move out as much of that complexity as possible from the user and into the system (Interaction Design Foundation, n.d.). Autofill in forms or checkout pages is a great example. Instead of forcing users to type in the same information a thousand times, the system automatically remembers it or completes it. The system manages the complexity of storing and accessing that information, rather than the user. This minimizes effort and improves the experience. The same is true of functions such as suggested email recipients or saved addresses. The system is doing more work so the user can do less.</p>

          <p>Simultaneously, Tesler’s Law instructs designers to not dumb things down to the point where users can’t grasp what is happening. There is always an element of complexity, and it has to be handled carefully. The idea isn’t to get rid of complexity altogether but to ensure users don’t store more of it than necessary.</p>

          <h3>Consistency & Feedback</h3>

          <p>Consistency is one of the easiest ways of alleviating cognitive burden. When a system behaves consistently across pages and features, users learn how it performs at an even higher rate. They don’t have to relearn new interactions when they transition to a new screen. That consistency not only informs user knowledge, but also encourages confidence building and builds user models. Consistent design allows users to move information from one part of a system to another, as Johnson also notes, which reduces the amount of thinking (Johnson, 2020).</p>

          <p>Feedback is also important. While users interact with a system, they want to know what’s happening. When they click an item that doesn’t work, they may believe the system didn’t perform in that way. If they turn in a form and do not receive confirmation, they may submit it again. Basic feedback, like loading and status indicators, progress bars, or confirmations, should help users know what the system is doing. This provides more confidence and means no doubt in which place. An excellent example of that is a website that displays a progress indicator at checkout. It lets users see where they are and what remains. That brings down memory demands, as users don’t need to mentalize how and where they are. They can just see it. That clear feedback keeps the users centered and enables them to progress.</p>

          <h3>Designing for Real Users</h3>

          <figure>
            <img src="images/thinking.jpg" alt="Person thinking while using laptop" style="width:60%; max-width:700px;">
            <figcaption>
              Photo by Adam Satria on Unsplash
            </figcaption>
          </figure>

          <p>What is interesting, if not shocking, is the generalization that systems frequently expect people to read instructions and spend time learning the interface. If nothing else, we learn how to respond at a faster pace. In fact, most users just dive right in and attempt to be able to accomplish what they need to do. This means that designers need to make systems comprehensible as they are being built. User advice should be embedded within the interface as opposed to trusting users to figure it out beforehand (Johnson, 2020). Designing for people means designing for real behavior. People skim, they forget things, they get distracted; they don’t always pay attention to instructions. Systems must accept that fact, not expect flawless users.</p>

          <p>Designers can make the whole thing feel easier and more intuitive when they reduce cognitive load, remain consistent, and offer transparent feedback. But memory and cognitive models are in all aspects very powerful in how people use technology. When systems recognise cognitive boundaries, and match known patterns of human engagement and behavior, instead users may focus on their own goals in place of its interface. Tesler's Law states that designers know that there will always be complexity, but complexity should always be taken care of by the system wherever possible. Designers can create systems that feel simple despite being complex by design through prioritizing consistency, feedback and reduced cognitive load.</p>

          <footer class="article-footer">
            <h3>Sources</h3>
            <ol>
              <li>
                Interaction Design Foundation. (n.d.). <em>Tesler’s law: The law of conservation of complexity</em>. https://www.interaction-design.org/literature/article/tesler-s-law-the-law-of-conservation-of-complexity
              </li>
              <li>
                Johnson, J. (2020). <em>Designing with the mind in mind</em> (3rd ed.). Elsevier. https://bookshelf.vitalsource.com/books/9780128182031
              </li>
              <li>
                Krug, S. (2014). <em>Don’t make me think, revisited: A common sense approach to web usability</em> (3rd ed.). New Riders.
              </li>
              <li>
                Yablonski, J. (2024). <em>Laws of UX</em> (2nd ed.). O’Reilly Media, Inc. https://cwu.vitalsource.com/books/9781098146924
              </li>
            </ol>
          </footer>
          </article>



         <!-- Module 2.3 Blog Post Starts here -->

         <!-- Module 3.1 Blog Post Starts here -->

         <!-- Module 3.2 Blog Post Starts here -->

      </main>
<!-- Page Footer  -->
      <footer class="page-footer">
       <p>Copyright &copy; 2025</p>
      </footer>
   </body>
</html>