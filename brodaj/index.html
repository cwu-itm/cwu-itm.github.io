<!DOCTYPE html>
<html lang="en">

<head>
   <meta charset="UTF-8">
   <meta name="viewport" content="width=device-width, initial-scale=1.0">
   <link href="css/styles.css" rel="stylesheet">
   <title>Joseph Broda | Portfolio</title>
</head>

<body>
   <!-- Page Header  -->
   <header class="page-header">
      <h1>Portfolio</h1>
   </header>
   <!-- Main Content Area  -->
   <main>
      <!-- Module 1.1 Blog Post Starts Here-->
      <article>
         <header class="article-header">
            <h2>Module 1.1 Blog Post</h2>
         </header>
         <h3>Systems Engineering: Not Just for Software</h3>
         <p>When you hear the words “Systems Engineering” what do you imagine? A data center with thousands of systems?
            Computer architecture? While those are great examples of a System, its true scope stretches far beyond this
            more widespread understanding. In Systems Engineering Demystified, Jon Holt (2023) defines Systems
            Engineering as "a conceptual framework based on the principle that the component parts of a system can best
            be understood in the context of the relationships with each other and with other systems, rather than in
            isolation” (p. 2).</p>
         <p>That definition is quite abstract and high-level. An easier way to think of Systems Engineering is looking
            at something as more than a sum of its parts. For example, a car is a system. It has multiple components,
            such as physical components (known as subsystems or system components), education, laws, regulations, and
            infrastructure, that are all designed to work together, and if looked at in isolation, its function and
            purpose start to fall a part. A cars’ brakes are a system that you can identify its function for in
            isolation, but its purpose doesn’t reveal itself until looked at as a whole. A car needs brakes to stop on
            the road without causing an accident and hurting someone. That one seemingly complete and isolated system
            actually calls upon the physical system (the physical brakes), the natural system of inertia and friction,
            and abstract systems of laws and safety regulations.</p>
         <p>While that example makes the concept of a system tangible, the true shift occurs in how we choose to think
            about it. Traditional, linear thinking is essentially a list-based approach to the world. It views problems
            as a straight line of cause and effect: if part A is broken, fix part A, and the problem is solved. This
            line of thinking assumes an implied balance that may be untouched in a simple system, but completely falls
            apart when complexity increases.</p>
         <p>In contrast, systems thinking is a mindset that shifts from looking at isolated events to identifying the
            underlying patterns and feedback loops that drive them. It recognizes that a system is is a set of things “…
            interconnected in such a way that they produce their own pattern of behavior over time” (Johnstone-Louis,
            2025). This means the relationships between components are just as important as the components themselves.
         </p>
         <p>In a digital or complex mechanical system, a linear fix often triggers unintended consequences elsewhere
            because it ignores these relationships. Systems thinking allows us to see the broader context and focus on
            root causes rather than just shallow, observable symptoms. If we only think linearly and compartmentalized,
            we risk being blindsided by change because we failed to see how our business or product relates to the wider
            web of interconnected systems.</p>
         <h3>The Pontiac Fiero: A Masterclass in Systems Failure</h3>
         <p>What happens when there is a complete breakdown of multi-discipline systems engineering? 1980s General
            Motors discovered the answer the hard way. In the late 1970s, GM faced a crisis: their “excitement
            division,” Pontiac, was not very exciting. Due to the 1973 and 1977 fuel crises and tightening emissions
            regulations, GM’s lineup was filled with heavy, sluggish cruisers. Meanwhile, small, efficient Japanese
            imports were eating away at their market share.</p>
         <p>This led to a radical idea: Project Pegasus. Later known as the Pontiac Fiero, it was designed as a
            mid-engine, two-seat car that offered the layout of a Ferrari for a fraction of the price. However, almost
            immediately, the Fiero was plagued by systemic failure from nearly every stakeholder.</p>
         <h4>The Three Evils: Complexity, Communication, and Understanding</h4>
         <p>The failure began with a lack of Understanding, one of the "three evils" of engineering identified by Jon
            Holt (2023). To get the project approved, Pontiac leadership had to "negotiate" the car's identity. They
            presented it to upper management not as a sports car, but as an efficient commuter. This created a
            fundamental conflict in Needs: Marketing wanted a sports car image to sell to young buyers, Engineering
            wanted a "performance" machine, but Accounting and Upper Management demanded a "high-MPG commuter" that
            wouldn't compete with the Corvette (Ruggieri, 2023).</p>
         <p>Because these stakeholders lacked a common language, the system boundaries were blurred. As Rick Brooks and
            Ryan Kaufman (2024) note, the systems engineer should act as the "translator" and the "negotiator" who
            adapts jargon into a common spoken language. In the Fiero’s case, the "negotiation" was a deception. The
            result was a car with a supercar silhouette but parts-bin internals: including a suspension from a Chevy
            Citation and an anemic, four-cylinder engine famously used in mail trucks.</p>
         <h4>A Marketing Nightmare </h4>
         <p>This stakeholder misalignment led to one of the greatest marketing blunders in automotive history. Marketing
            ran with its baby Ferrari look, but the constraints forced by the commuter car label meant the car was
            chronically slow. They famously touted a “50 MPG” rating to satisfy the fuel-efficiency requirements, yet
            this figure was only achievable on the absolute slowest, most stripped-down version of the car that no one
            actually bought. </p>
         <p>This is a classic example of essential vs. accidental complexity. The essential complexity of a mid-engine
            car is that it is hard to cool and also looked really cool to buyers who then demanded performance to back
            up the looks. Accidental complexity was introduced by the inefficiencies in people, process, and tooling
            (Holt, 2023, p. 15). By using a mail-truck engine and inadequate suspension and brakes from existing
            platforms to save money, GM created a system where the parts were fundamentally at war with the package.</p>
         <h4>Complexity and Firey Consequences</h4>
         <p>This leads to the final evil: complexity. To reach those high MPG goals, stay under budget, and fit within
            the constraint of a cramped engine bay, the team used a smaller than ideal oil pan. This linear decision to
            save space, weight, and cost ignored the natural system of thermal dynamics. Because the car was
            mid-engined, airflow in the engine bay was restricted.</p>
         <p>The systematic consequence was catastrophic. If an owner of a sporty car wanted to do sporty driving, they
            risked oil starvation. And because the pan was so small, this was not hard to achieve. Oil would run
            low, the engine would overheat in its cramped, unventilated box, and eventually the overstressed engine
            block would crack. This allowed oil to leak onto hot exhaust components, leading to fires. The Fiero became
            a systems nightmare because the stakeholders failed to agree on what the car was as a whole. You cannot
            change the engine and oil capacity without affecting the thermal safety of the entire vehicle, especially
            when shoehorning in a drivetrain that was never designed around mid-engine constraints. The end-user, the
            most important stakeholder, was left with a car that looked like a rocket but drove like a tractor, and
            occasionally, caught fire.</p>
         <h3>The Model-Based Systems Engineering as a Single Source of Truth</h3>
         <p>The Fiero was a victim of “siloed” information. Accounting had their spreadsheets, Marketing had their
            brochures, and Engineering had their blueprints. Because these stakeholders were working from different
            documents and points of view, a fragmented truth emerged where the deception that the car was a commuter
            rather than a sports car could live in the gaps between piles of paper. In today’s complex digital systems,
            where components are invisible and move at high speed, this fragmentation is a death sentence. This is why
            Model-Based Systems Engineering (MBSE) is applicable. It replaces disconnected documents with a single
            source of truth. In a model, every requirement and constraint is linked. If a stakeholder, like accounting
            or product managers, decides to cut costs by reducing infrastructure capacity, the model automatically
            reflects that change through the entire architecture, immediately flagging that the user experience or
            security requirements are no longer being met.</p>
         <p>As Rick Brooks and Ryan Kaufman (2024) argue, the systems engineer must be the negotiator who holds the team
            together, and in a digital system, the model is the negotiator’s strongest tool. It prevents the kind of
            “stretching the truth” that doomed the Fiero because you cannot hide a systematic flaw when a digital model
            shows a red line connecting a cost-cutting measure to a system-wide failure. Jon Holt (2023) notes that a
            model is a simplification of reality that allows us to understand these invisible relationships before they
            manifest as disasters. By modeling “what-if” scenarios, digital architects can see an escapable consequence
            before it becomes inescapable.</p>
         <h3>Legacy</h3>
         <p>The silver lining in the Fiero story is that it may not be as total a failure as popular history suggests.
            While sales plummeted from 140,000 units at its 1984 debut to just 47,000 by its cancellation in 1988, its
            lessons rippled throughout the larger GM "system of systems." Most famously, the plastic body panels the
            Fiero revolutionized became the signature feature of Saturn, a brand that successfully fought off imports
            for years by prioritizing the very stakeholder communication GM had previously lacked. The Fiero eventually
            gave GM the technical confidence to build world-class mid-engine cars, a journey that ironically culminated
            in the 2020 Corvette C8.</p>
         <p>However, General Motors as a whole also serves as a warning that tools like MBSE are only as effective
            as the culture using them. Even with the advent of modern digital modeling, GM later suffered from the
            Cobalt
            ignition switch scandal, where GM management willingly ignored critical flaws in the Chevrolet Cobalt and
            its
            platform-mates, leading to multiple deaths (Basu, 2014). This proves that technical models cannot fix a
            fundamental breakdown in the Three Evils. Systems engineering is a multidisciplinary approach that must
            include management and law (Holt, 2023). If the human stakeholders choose to ignore the flaws discovered by
            the model, the system will still fail.</p>
         <p>As a Fiero owner, the car’s flaws are baffling, yet they are a testament to the fact that systems thinking
            is the only way to bridge the gap between a "supercar" dream and the reality of a safe, reliable machine.
            Whether we are building a mid-engine sports car or a complex digital network, we must remember that if the
            stakeholders aren't on the same page, the system will eventually find a way to catch fire.</p>
         <footer class="article-footer">
            <h3>Sources:</h3>
            <ol>
               <li>Basu, T. (2014, March 31). <em>Timeline: A History Of GM’s Ignition Switch Defect</em>. NPR. <a
                     href="https://www.npr.org/2014/03/31/297158876/timeline-a-history-of-gms-ignition-switch-defect">https://www.npr.org/2014/03/31/297158876/timeline-a-history-of-gms-ignition-switch-defect</a>
               </li>
               <li>Brooks, R., & Kaufman, R. (2024, April 22). <em>The Role of Systems Engineering in the Development of
                     Innovative Technologies</em>. Inside Battelle; Battelle. <a
                     href="https://inside.battelle.org/blog-details/the-role-of-systems-engineering-in-the-development-of-innovative-technologies">https://inside.battelle.org/blog-details/the-role-of-systems-engineering-in-the-development-of-innovative-technologies</a>
               </li>
               <li>Camisa, J. (2022, November 17). <em>The Pontiac Fiero was A 50-mpg Con Job - Full History - Jason
                     Cammisa’s Revelations Ep. 27</em>. YouTube; Hagerty. <a
                     href="https://www.youtube.com/watch?v=anHmoiS6QeY">https://www.youtube.com/watch?v=anHmoiS6QeY</a>
               </li>
               <li>Holt, J. (2023). <em>Systems Engineering Demystified</em> (2nd ed.). Packt Publishing Ltd.</li>
               <li>Johnstone-Louis, M. (2025, April 25). <em>Today’s Most Crucial Leadership Skill Is Systems
                     Thinking</em>. Forbes. <a
                     href="https://www.forbes.com/sites/maryjohnstone-louis/2025/04/25/todays-most-crucial-leadership-skill-is-systems-thinking/">https://www.forbes.com/sites/maryjohnstone-louis/2025/04/25/todays-most-crucial-leadership-skill-is-systems-thinking/</a>
               </li>
               <li>Ruggieri, L. (2023, February 2). <em>Pontiac Fiero History and FAQ: GM’s Most Famous Failure?</em>
                  MotorTrend. <a
                     href="https://www.motortrend.com/features/pontiac-fiero">https://www.motortrend.com/features/pontiac-fiero</a>
               </li>
            </ol>
         </footer>
      </article>

      <!-- Module 1.2 Blog Post Starts here -->
      <article>
         <header class="article-header">
            <h2>Module 1.2 Blog Post</h2>
         </header>
         <p>
            Whenever we design a system, it’s easy to get caught up in the immediate build phase. Everyone’s excited to
            get something implemented and create something new. However, among this excitement, we need someone to
            think:
            “how can we maintain this into the future?” In Systems Engineering Demystified, Jon Holt (2023) defines a
            Life Cycle as a way to define the evolution of a system over time, providing a representation of how that
            system moves from conception to retirement.
         </p>
         <p>This is called the Systems Development Life Cycle (SDLC). At its core, the SDLC is a framework used to
            manage the complexities of planning, creating, testing, deploying, and managing a system. Without this
            framework, we risk falling into the “Three Evils”: Lack of understanding, communication, and complexity
            (Holt, 2023). These stages ensure that every stakeholder is on the same page about the system’s current
            state and future needs.</p>
         <p>Digital systems, being intangible pools of 1’s and 0’s, are never truly static like you’d see in an
            infrastructure or manufacturing project. Even if the core product is locked in, elements outside of your
            control like dependencies, protocols, and system architectures can change at a moment’s notice. If you view
            your project as finished the moment a system is up and running, you are setting yourself up for failure. By
            following SDLC, you are acknowledging that the system will eventually need refactoring or retirement (Holt,
            2023). This mindset forces one to plan for things like data migration and security patching before they
            become emergencies to ensure the system remains sustainable and secure throughout its entire lifespan.</p>
         <h3>SDLC Models</h3>
         <p>There’s no one-size-fits-all approach to building a system. Instead, we have to choose between different
            models based on our goals, timeline, and tolerance for messiness.</p>
         <h4>Linear: No U-Turns Allowed</h4>
         <p>The Linear model, often referred to as “Waterfall”, is essentially linear thinking applied to systems
            engineering. It follows a strict, logical sequence: you finish one stage completely before moving to the
            next. In a perfect world, this works great. You define your needs, design the system, build it, test it,
            ship it, and you’re done.</p>
         <p>The advantage of this model is predictability. Because the requirements are locked in from the start, it’s
            easier to manage budgets and milestones. However, the drawback is its extreme rigidity. In software and IT,
            you rarely know what you need on day one. If you are halfway through the build phase and a new, better
            technology comes out or a new security vulnerability has been discovered, the model makes it very difficult
            to go back.</p>
         <p>This creates a massive risk during the verification, where each stage of development should be verified
            against its requirements. In a linear model, you don’t actually verify that the system works for the user
            until the very end. If you realize in testing that the initial requirements were misunderstood or are now
            obsolete, you have already spent your project’s budget. You are essentially stuck shipping an insecure,
            outdated system because it is too expensive and time-consuming to fix.</p>
         <h4>Iterative: A Living Document</h4>
         <p>In contrast, the Iterative model treats the system like a living document. Rather than building the whole
            thing in one shot, you build a rough draft of the entire system, test it, and then refine it in cycles. This
            is essentially “trial and error” with a plan.</p>
         <p>This model allows for immense flexibility because it prioritizes the feedback loop. You get to see a working
            version of the system much earlier in the process, which allows you to catch major flaws in logic or user
            experience before they are set in stone. However, the danger of a system that is never truly done is scope
            creep. Because stakeholders see a functional prototype early on, they often suggest constant changes.
            Without the strict decision gates Holt (2023) mentions, points where you must stop and agree that a stage is
            finished, an iterative project can spiral out of control. You might find yourself in an endless loop of
            refining the perfect interface while the actual system remains unfinished.</p>
         <h4>Incremental: Ship Now, Fix Later</h4>
         <p>The Incremental model is about shipping a Minimum Viable Product (MVP) and doing the rest later. You break
            the system into chunks and deliver them one by one. This is highly efficient for getting a system into the
            hands of users quickly, but it is also where we see the most dangerous accumulation of technical debt.</p>
         <p>Technical debt, as defined by Tim Mucci (2025), refers to the future costs associated with relying on
            short-term or suboptimal decisions during development. When you ship an MVP, you often take shortcuts to
            meet a deadline, promising to go back and clean up code or documentation later. In reality, later rarely
            comes. And as I’ve learned in my years of automotive work, there’s nothing more permanent than a temporary
            fix.</p>
         <p>
            We can see the crust of this debt in the Windows operating system. One of Windows 11’s biggest marketing
            points is a sleek, modern interface and modern reinterpretations of classic Windows apps. Yet if you dig
            just two or three layers deep into the settings or poke around system utilities, you’ll discover the horror
            of UI/UX elements that haven’t been touched since the Clinton administration, and sometimes even older.
            This is the result of decades of incremental additions and backwards compatibility requirements. Microsoft
            chose the short-term benefit of keeping old apps working, which satisfies the needs of the enterprise, one
            of Microsoft’s biggest stakeholders, over the long-term sustainability of a clean, modern architecture.
            While this meets immediate business needs (Mucci, 2025), the interest on that debt is a system that becomes
            increasingly bloated and harder to secure over time. And if you look at the sheer amount of bugs and
            performance inconsistencies in modern Windows, it’s clear that the interest has compounded to a breaking
            point. It feels as though the debt collectors have finally arrived, and Microsoft is being forced to pay
            for decades of shortcuts with the stability of their software.</p>
         <h3>Reflection on Design, Sustainability, and Evolution</h3>
         <p>Sustainability in IT is often measured by human capital. We usually think of a system as a set of servers
            and code, but it also requires a steady supply of people who understand how it works. This is where the SDLC
            is critical. Abhay Talreja (2024) discusses how legacy systems are often “so deeply embedded in the
            operational fabric” of a business that they become nearly impossible to remove.</p>
         <p>
            You see this in the finance industry, where some institutions are still running on Fortran or COBOL code
            from over half a century ago. These developers are practically worth their weight in gold because they are
            the only ones left who can navigate this level of digital archaeology. When a system reaches this point, it
            is no longer sustainable. It is a zombie system that stays alive not because it’s efficient or the best way
            to do it, but because the risk of changing it is higher than the massive cost of keeping it on life support.
            This is the worst-case consequence of ignoring the retirement stage of the SDLC. You eventually become a
            prisoner to your own infrastructure.</p>
         <p>However, there is another side to this legacy trap. In some systems, like the point-of-sales terminals you
            see emulating ancient Unix interfaces at a grocery store, stay in place because of a “if it ain’t broke,
            don’t fix it” philosophy. Over decades of refinement and bug-squashing, these systems have become nearly
            indestructible. While they look like relics, their code has been polished to a point of reliability and
            resiliency that modern, more complex software often struggles to reach.</p>
         <p>This creates a paradox for sustainability. On one hand, you have a system that is incredibly stable and
            reliable. On the other hand, you’re still accruing what Tim Mucci (2025) describes as the future costs of
            technical debt. Even if the system is solid, the world around it is moving towards new standards and
            security protocols. By choosing to stay with a perfected legacy system, you are essentially betting that the
            cost of maintaining that archaic infrastructure will never exceed the cost of a catastrophic failure during
            an upgrade. It is a fine line between a system that is battle-tested and one that is simply waiting for its
            last expert to retire.</p>
         <h3>Conclusion</h3>
         <p>Whether you are looking at the rigid structure of a linear model or the living document approach of
            iterative design, it becomes clear that these frameworks are not rules to be followed blindly. They are a
            balance of trade-offs. There is no correct way to build a system; there is only the way that best aligns
            with your specific objectives and the needs of your stakeholders. A high-security government database might
            require the slow, verified pace of a linear cycle, while a consumer-facing app might need the rapid feedback
            loops of an incremental rollout. The goal isn’t to pick the best model because a textbook said so; it
            requires careful thinking from the very start of the system’s inception. </p>
         <footer class="article-footer">
            <h3>Sources:</h3>
            <ol>
               <li>Holt, J. (2023). <em>Systems Engineering Demystified</em> (2nd ed.). Packt Publishing Ltd.</li>
               <li>Mucci, T. (2025, March 27). <em>Technical debt</em>. Ibm.com. <a
                     href="https://www.ibm.com/think/topics/technical-debt">https://www.ibm.com/think/topics/technical-debt</a>
               </li>
               <li>Talreja, A. (2024, April 19). <em>Managing Legacy Systems: With a Case Study on Modernization –
                     Nextra</em>. Teachingagile.com. <a
                     href="https://teachingagile.com/sdlc/maintenance/managing-legacy-systems">https://teachingagile.com/sdlc/maintenance/managing-legacy-systems</a>
               </li>
            </ol>
         </footer>
      </article>
      <!-- Module 2.1 Blog Post Starts here -->
      <article>
         <header class="article-header">
            <h2>Module 1.2 Blog Post</h2>
         </header>
         <p>Human-Centered Design (HCD) is the philosophy of designing around ourselves. On the surface, that sounds
            like it should be an easy task: who would know us better than us? In practice, reality is rarely that ideal.
            HCD is often one of the most difficult parts of a system, physical or digital, to get right. Humans are
            complex, unpredictable, and fickle beings.</p>
         <p>We aren't without a guiding star, however. Two major trains of thought have risen to try to make sense of
            our madness: ISO 9241-210 and the IDEO Field Guide. ISO defines HCD as an approach that makes systems usable
            by focusing on the users, their needs, and requirements. It's a systematic process. You understand the
            context, specify the requirements, build a solution, and evaluate it against those requirements. It is
            logical and rigid, but perhaps a bit too idealized and removed from reality for the type of systems we use
            every day. In contrast, IDEO treats HCD more like art and culture. It is an ethnographic approach, studying
            how real humans adapt real systems to get real things done.</p>
         <p>Both perspectives agree on one thing: you can't design a system in a vacuum. You have to start with the
            fundamentals of the human brain.</p>
         <p></p>Take something as simple as a digital checkbox. In a modern UI, it might just be two thin lines forming
         a
         square and a check (☑). Yet, the reason we instinctively know that clicking the box selects an item isn't
         because we were born with that knowledge. Our hunter-gatherer forefathers had no use for written ballots
         when gathering berries. It's because the design is a skeuomorph of a physical ballot. We are leveraging an
         existing mental model, a concept Jakob's Law tells us is vital because users spend most of their time using
         other products (Yablonski, 2024). They expect your system to follow the "laws of physics" they've already
         learned elsewhere.</p>
         <p>This reliance on the familiar is a result of how our perception is biased by past experience. As Jeff
            Johnson (2020) explains, our brains are not neutral recorders of information: they are constantly filtering
            the present through the lens of what we have seen before. When we see that square box, our perceptual
            priming kicks in, allowing us to identify its function instantly without conscious thought (Johnson, 2020).
         </p>
         <p>When we ignore these established ideas in favor of being innovative or different, we aren't just changing a
            coat of paint; we are breaking the fundamental mental maps we've built up over the years. By breaking from
            established visual structures, we force the brain to spend precious cycles trying to figure out how to use
            the tool rather than actually using it to achieve a goal.</p>
         <h3>Visual Noise</h3>
         <p>In the early days of consumer electronics, designers were terrified that users wouldn't know how to interact
            with a glass screen. To fix this, they leaned heavily into skeuomorphism, or making digital elements look
            like their physical counterparts (Fabunan, 2025). The notes app was a yellow legal pad with a torn paper
            texture at the top. The calendar app was bound by leather. The compass had a brushed-metal finish and glass
            reflections. </p>
         <p>At first, this was a brilliant application of Jakob's Law. By making a digital button look exactly like a
            user's light switch, the learning curve was steeply reduced by leveraging the user's existing mental models.
            However, as technology matured and people became more comfortable with their glowing glass and aluminum
            rectangles, we hit a point of diminishing returns. The design shifted from being a helpful shorthand to
            visual noise.</p>
         <p>This is mental bloat. When you shoehorn woodgrain textures and linen patterns into an interface, you are
            adding non-functional data that the human brain still has to process. This is where we run into Hick's Law.
            The time it takes to make a decision increases with the complexity of the decision (Yablonski, 2024). When a
            user's eyes have to navigate through deviated leather stitching in their phonebook just to find the "Add
            Contact" button, you are slowing them down.</p>
         <p>This also gets in the way of Miller's Law. Our working memory is a finite resource (Yablonski, 2024). In a
            clean system, these slots in our memory are used for navigation and our perceived outcome of the action. In
            a heavily skeumorphic system, some of that mental real estate is wasted on processing decorative textures.
            And when a user eventually becomes desensitized to the bells and whistles, the man-hours it took to craft
            the wooden bookshelf for the ebook app and the digital cows taken from us to wrap our calendar app in
            digital leather go to waste.</p>
         <p>Jeff Johnson (2020) points out that our vision is optimized to see structure. When an interface is busy,
            the visual hierarchy collapses. The brain struggles to distinguish the foreground (the button you need to
            press) from the background (the textures and window chrome). We were so focused on making the digital world
            a facsimile of real life that we forgot that the digital world was supposed to let us escape from the
            inefficiencies of reality.</p>
         <h3>An Overcorrection</h3>
         <p>The industry's response to the clutter of the late 2000s and early 2010s was known as flat design. If
            skeumorphism was a cluttered garage, flat design was an empty white room. Many people wave the whole
            movement away as cheap mediocrity, but I disagree. Good flat design, like iOS 7 or early iterations of
            Google's Material Design, didn't actually get rid of skeuomorphs. It distilled them into their most basic
            elements. It removed the superfluous veneer of woodgrain and cloth that cluttered their predecessors, but
            kept the functional skeuomorphs, like subtle shadows to show depth, motion to show what an action did, and
            simple but recognizable icons that reference the same existing mental models that the more elaborate
            classical skeuomorphic designs were built around.</p>
         <p>This was originally a victory for cognitive efficiency. By stripping away the leather stitching, designers
            intended to satisfy Hick's Law by making the content the sole focus. However, we've recently witnessed this
            trend spiral into what I can only define as a Catastrophe of Contrast. Take Google's Material 3, for
            example. In an attempt to be ultra-modern, it has strayed too far from its initial intention of "digital
            paper." They've created a visual hierarchy nightmare by basing their entire UI on tinted off-white
            backgrounds and dynamic color palettes that bleed into the interface elements. It's got the eye candy, but
            none of the home-grown charm of classical skeuomorphism. It's the worst of both worlds.</p>
         <p>When everything is a soft pastel shade and borders are removed to look cleaner, the interface no longer
            provides the pops of contrast our peripheral vision needs to guide our central vision toward the next action
            (Johnson, 2020). This creates what Kate Moran (2015) calls "click uncertainty," where weak visual signifiers
            condition users to hover tentatively across a page rather than navigating with confidence. Instead of the
            interface providing clear signifiers, the user is forced to rely on pure memorization. This is a failure of
            human-centered design because our vision is biologically optimized to see edges and contrast, not subtle
            shade variations (Johnson, 2020).</p>
         <p>This creates a massive conflict with Fitts's Law. While the law is mathematically about the size and
            distance of a target (Yablonski, 2024), it assumes the user can actually identify where that target is. In
            this contrast catastrophe, buttons become indistinguishable from the background, and the physical structure
            of the interface turns into a blur of nearly identical hues. By prioritizing a clean aesthetic over the way
            human vision actually works, these modern design systems not only fail basic human-centered design, they're
            repeating the clutter and noise we've been trying to move away from.</p>
         <h3>The Middle Ground</h3>
         <p>The history of UI and UX design has shown that designers tend to prefer the extremes, whether it's wood
            details or a complete lack of detail. Both extremes fail because they prioritize an aesthetic trend over the
            person behind the glass. True human-centered design lives in the middle ground with distilled skeuomorphs to
            provide structure without the noise.</p>
         <p>This balance is where the two primary frameworks of HCD finally meet. The ISO 9241-210 standard demands a
            system that is effective and efficient. By removing the digital woodgrain, we satisfy this by reducing the
            cognitive load and decision time defined by Hick's Law and Miller's Law. However, a system that is purely
            efficient but visually invisible fails the test of satisfaction. This is where the IDEO Field Guide
            perspective is vital. It reminds us that design requires empathy for the human experience. We keep the
            subtle shadow under a button or the check in a checkbox because it respects the user's existing mental
            models. It is an acknowledgment that our brains are still tied to the physical world (Johnson, 2020).</p>
         <p>Proper human-focused design is understanding that design is a tool to contextualize ourselves before letting
            it melt away and accomplish a task. It is the art of balancing the familiarity of the physical world with
            the efficiency of the digital one, and when either one of those goes out of balance, the whole system fails.
         </p>
         <footer class="article-footer">
            <h3>Sources:</h3>
            <ol>
               <li>Fabunan, A. (2025, March 26). <em>Skeuomorphism in UX: Definitions, examples, and its relevance
                     today</em>. LogRocket Blog. <a
                     href="https://blog.logrocket.com/ux-design/skeuomorphism-ux-design-examples/">https://blog.logrocket.com/ux-design/skeuomorphism-ux-design-examples/</a>
               </li>
               <li>Johnson, J. (2020). <em>Designing with the Mind in Mind: simple guide to understanding user
                     interface design guidelines</em>. Morgan Kaufmann Publisher.</li>
               <li>Moran, K. (2015, November 8). <em>Long-Term Exposure to Flat Design: How the Trend Slowly Makes Users
                     Less Efficient</em>. Nielsen Norman Group. <a
                     href="https://www.nngroup.com/articles/flat-design-long-exposure/">https://www.nngroup.com/</a>
               </li>
               <li>Yablonski, J. (2024). <em>Laws of UX</em>. O'Reilly Media, Inc.</li>
            </ol>
         </footer>
      </article>
      <!-- Module 2.2 Blog Post Starts here -->

      <!-- Module 2.3 Blog Post Starts here -->

      <!-- Module 3.1 Blog Post Starts here -->

      <!-- Module 3.2 Blog Post Starts here -->

   </main>
   <!-- Page Footer  -->
   <footer class="page-footer">
      <p>Copyright &copy; 2026</p>
   </footer>
</body>

</html>